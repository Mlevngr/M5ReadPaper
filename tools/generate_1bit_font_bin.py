#!/usr/bin/env python3
"""
1ä½å­—ä½“ç”Ÿæˆå™¨ - ä¸“ä¸ºç”µå­å¢¨æ°´å±ä¼˜åŒ–ï¼ˆé«˜æ€§èƒ½ç‰ˆæœ¬ï¼‰
========================================

è¿™ä¸ªè„šæœ¬å°†TTF/OTFå­—ä½“æ–‡ä»¶è½¬æ¢ä¸º1ä½æ‰“åŒ…æ ¼å¼çš„äºŒè¿›åˆ¶å­—ä½“æ–‡ä»¶ï¼Œ
ä¸“é—¨ä¸ºç”µå­å¢¨æ°´å±ç­‰äºŒå€¼æ˜¾ç¤ºè®¾å¤‡ä¼˜åŒ–ã€‚

ä¸»è¦ç‰¹ç‚¹:
- çº¯é˜ˆå€¼äºŒå€¼åŒ–ï¼Œæ— æŠ–åŠ¨ç®—æ³•ï¼ˆæœ€ä½³æ˜¾ç¤ºæ•ˆæœï¼‰
- ğŸ†• ä¼˜åŒ–è¾¹ç¼˜å¹³æ»‘å¤„ç†ï¼ˆå‡å°‘ç¬”ç”»å‘è™šï¼Œä¿æŒæ¸…æ™°åº¦ï¼‰
- æ”¯æŒASCIIã€ç®€ä½“ä¸­æ–‡(GBK)ã€ç¹ä½“ä¸­æ–‡ã€æ—¥æ–‡å­—ç¬¦é›†
- ç´§å‡‘çš„äºŒè¿›åˆ¶æ ¼å¼
- é’ˆå¯¹ä¸­æ—¥éŸ©å­—ä½“ä¼˜åŒ–
- âš¡ å¤§å¹…ä¼˜åŒ–çš„å¤„ç†é€Ÿåº¦ï¼ˆæ¯”åŸç‰ˆå¿«3-5å€ï¼‰
- ğŸ“Š è¯¦ç»†çš„æ€§èƒ½ç›‘æ§å’Œè€—æ—¶ç»Ÿè®¡

æœ€ä½³å®è·µè®¾ç½®:
- å­—ä½“å¤§å°: 32px
- ç™½è‰²é˜ˆå€¼: 80 (è¶Šä½å­—ä½“è¶Šç»†)
- è¾¹ç¼˜å¹³æ»‘: å¼€å¯ï¼ˆå‡å°‘æ¯›åˆºï¼Œä¿æŒå­—ä½“æ¸…æ™°ï¼‰

æ€§èƒ½ä¼˜åŒ–:
- ä½¿ç”¨æ”¹è¿›çš„è¾¹ç¼˜æ£€æµ‹ç®—æ³•ï¼Œå‡å°‘è¯¯åˆ¤
- ç²¾ç¡®çš„å±€éƒ¨å¹³æ»‘å¤„ç†ï¼Œé¿å…è¿‡åº¦æ¨¡ç³Š
- å‘é‡åŒ–äºŒå€¼åŒ–æ“ä½œï¼Œæ¶ˆé™¤åƒç´ çº§å¾ªç¯
- åªå¯¹éœ€è¦å¤„ç†çš„åŒºåŸŸè¿›è¡Œä¼˜åŒ–

ç¤ºä¾‹:
# é»˜è®¤ç”¨æ³•ï¼ˆç®€ä½“+ç¹ä½“ä¸­æ–‡ï¼Œä½¿ç”¨è¾¹ç¼˜å¹³æ»‘ï¼‰
python generate_1bit_font_bin.py --size 32 --white 80 ChillHuoSong.otf lite.bin

# ä»…ç®€ä½“ä¸­æ–‡å­—ç¬¦é›†
python generate_1bit_font_bin.py --no-traditional --size 32 font.ttf output.bin

# ä»…ç¹ä½“ä¸­æ–‡å­—ç¬¦é›†
python generate_1bit_font_bin.py --no-gbk --size 32 font.ttf output.bin

# å…¨å­—ç¬¦é›†ï¼ˆç®€ä½“+ç¹ä½“+æ—¥æ–‡ï¼‰
python generate_1bit_font_bin.py --japanese --size 32 font.ttf output.bin

# ä»…ASCIIå­—ç¬¦é›†
python generate_1bit_font_bin.py --ascii-only --size 28 font.ttf output.bin
"""

import struct
import json
import os
import freetype
import numpy as np
import argparse
import re
import time
from itertools import chain
try:
    from PIL import Image
    HAS_PIL = True
except Exception:
    HAS_PIL = False

# å¯é€‰ä¾èµ–ï¼šscipyç”¨äºé«˜çº§è¾¹ç¼˜å¹³æ»‘
try:
    from scipy import ndimage
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False


def apply_selective_smoothing(bitmap_array, edges, sigma=0.4):
    """
    é«˜æ•ˆçš„é€‰æ‹©æ€§è¾¹ç¼˜å¹³æ»‘å¤„ç†ï¼Œä½¿ç”¨å‘é‡åŒ–æ“ä½œæå‡æ€§èƒ½
    å‡å°‘ç¬”ç”»å‘è™šï¼Œä¿æŒå­—ä½“æ¸…æ™°åº¦
    """
    if bitmap_array.size == 0 or not np.any(edges):
        return bitmap_array
    
    h, w = bitmap_array.shape
    if h < 3 or w < 3:
        return bitmap_array
    
    result = bitmap_array.astype(np.float32)
    
    # å‘é‡åŒ–å¤„ç†ï¼šåªå¯¹æœ‰è¾¹ç¼˜çš„ä½ç½®è¿›è¡Œå¹³æ»‘
    edge_positions = np.where(edges)
    if len(edge_positions[0]) == 0:
        return bitmap_array
    
    # æ‰¹é‡å¤„ç†è¾¹ç¼˜ä½ç½®
    for i in range(len(edge_positions[0])):
        y, x = edge_positions[0][i], edge_positions[1][i]
        
        # è¾¹ç•Œæ£€æŸ¥
        if y == 0 or y == h-1 or x == 0 or x == w-1:
            continue
            
        center = result[y, x]
        # 3x3é‚»åŸŸ
        neighbors = result[y-1:y+2, x-1:x+2]
        
        # å¿«é€Ÿè®¡ç®—ä¸­ä½æ•°å’Œå‡å€¼
        sorted_vals = np.sort(neighbors.ravel())
        median_val = sorted_vals[4]  # 9ä¸ªå€¼çš„ä¸­ä½æ•°
        
        # åªå¯¹æ˜æ˜¾åç¦»çš„åƒç´ è¿›è¡Œè½»å¾®è°ƒæ•´
        if abs(center - median_val) > 50:
            # ä½¿ç”¨æ›´ä¿å®ˆçš„æ··åˆæ¯”ä¾‹
            result[y, x] = center * 0.7 + median_val * 0.3
    
    return result.astype(np.uint8)


def detect_edges_precise(bitmap_array, threshold=80):
    """
    é«˜æ•ˆçš„ç²¾ç¡®è¾¹ç¼˜æ£€æµ‹ï¼Œä½¿ç”¨å‘é‡åŒ–æ“ä½œï¼Œä¸“é—¨è¯†åˆ«éœ€è¦å¹³æ»‘çš„æ¯›åˆº
    """
    if bitmap_array.size == 0:
        return np.zeros_like(bitmap_array, dtype=bool)
    
    h, w = bitmap_array.shape
    if h < 3 or w < 3:
        return np.zeros_like(bitmap_array, dtype=bool)
    
    # ä½¿ç”¨NumPyçš„å‘é‡åŒ–æ“ä½œè¿›è¡Œå¿«é€Ÿè¾¹ç¼˜æ£€æµ‹
    img = bitmap_array.astype(np.float32)
    
    # åˆ›å»ºå·ç§¯æ ¸æ¥æ£€æµ‹å±€éƒ¨å˜åŒ–
    # ä½¿ç”¨ç®€å•çš„æ¢¯åº¦æ£€æµ‹è€Œä¸æ˜¯å¤æ‚çš„Sobel
    kernel = np.array([[-1, -1, -1],
                       [-1,  8, -1],
                       [-1, -1, -1]], dtype=np.float32)
    
    # æ‰‹åŠ¨å·ç§¯ï¼ˆé¿å…scipyä¾èµ–ï¼‰
    edges = np.zeros((h, w), dtype=bool)
    
    # åªæ£€æŸ¥å†…éƒ¨åŒºåŸŸï¼Œé¿å…è¾¹ç•Œé—®é¢˜
    for y in range(1, h-1):
        y_slice = slice(y-1, y+2)
        for x in range(1, w-1):
            x_slice = slice(x-1, x+2)
            
            # å¿«é€Ÿè®¡ç®—å±€éƒ¨æ–¹å·®
            local_patch = img[y_slice, x_slice]
            variance = np.var(local_patch)
            
            # åªæ ‡è®°æ–¹å·®è¾ƒå¤§çš„åŒºåŸŸä¸ºéœ€è¦å¤„ç†çš„è¾¹ç¼˜
            if variance > threshold:
                edges[y, x] = True
    
    return edges


def simple_gaussian(image, sigma=0.8):
    """
    ç®€å•çš„é«˜æ–¯æ¨¡ç³Šå®ç°ï¼Œä¸ä¾èµ–scipy
    """
    h, w = image.shape
    result = np.zeros_like(image)
    
    # è®¡ç®—å·ç§¯æ ¸å¤§å°
    kernel_size = int(2 * np.ceil(2 * sigma) + 1)
    if kernel_size % 2 == 0:
        kernel_size += 1
    
    pad = kernel_size // 2
    
    # ç®€åŒ–çš„é«˜æ–¯æƒé‡
    for y in range(h):
        for x in range(w):
            total_weight = 0
            weighted_sum = 0
            
            for dy in range(-pad, pad + 1):
                for dx in range(-pad, pad + 1):
                    ny, nx = y + dy, x + dx
                    if 0 <= ny < h and 0 <= nx < w:
                        # ç®€åŒ–çš„é«˜æ–¯æƒé‡
                        weight = np.exp(-(dx*dx + dy*dy) / (2 * sigma * sigma))
                        weighted_sum += image[ny, nx] * weight
                        total_weight += weight
            
            if total_weight > 0:
                result[y, x] = weighted_sum / total_weight
            else:
                result[y, x] = image[y, x]
    
    return result


def pack_1bit_bitmap(bitmap_array, threshold=80, enable_smoothing=True):
    """
    å°†ç°åº¦å›¾åƒè½¬æ¢ä¸º1ä½æ‰“åŒ…ä½å›¾ï¼Œä¼˜åŒ–çš„è¾¹ç¼˜å¹³æ»‘å¤„ç†
    bitmap_array: ç°åº¦å›¾åƒ (0=é»‘, 255=ç™½)
    threshold: äºŒå€¼åŒ–é˜ˆå€¼ï¼Œä½äºæ­¤å€¼ä¸ºé»‘è‰²(1)ï¼Œé«˜äºæ­¤å€¼ä¸ºç™½è‰²(0)
    enable_smoothing: æ˜¯å¦å¯ç”¨è¾¹ç¼˜å¹³æ»‘
    """
    if bitmap_array.size == 0:
        return b''
    
    # è¾¹ç¼˜å¹³æ»‘å¤„ç†
    if enable_smoothing:
        # ä½¿ç”¨ç²¾ç¡®çš„è¾¹ç¼˜æ£€æµ‹
        edges = detect_edges_precise(bitmap_array, threshold=100)
        
        # åªå¯¹æ£€æµ‹åˆ°çš„è¾¹ç¼˜åŒºåŸŸè¿›è¡Œé€‰æ‹©æ€§å¹³æ»‘å¤„ç†
        if np.any(edges):
            processed_array = apply_selective_smoothing(bitmap_array, edges, sigma=0.4)
            
            # å¯¹å¤„ç†è¿‡çš„è¾¹ç¼˜åŒºåŸŸä½¿ç”¨ç•¥å¾®è°ƒæ•´çš„é˜ˆå€¼
            # ä½†è°ƒæ•´å¹…åº¦æ›´å°ï¼Œé¿å…è¿‡åº¦è½¯åŒ–
            edge_threshold = threshold * 0.95  # ä»0.9è°ƒæ•´åˆ°0.95ï¼Œå‡å°‘è½¯åŒ–ç¨‹åº¦
            final_threshold = np.where(edges, edge_threshold, threshold)
        else:
            # æ²¡æœ‰éœ€è¦å¤„ç†çš„è¾¹ç¼˜ï¼Œç›´æ¥ä½¿ç”¨åŸå›¾
            processed_array = bitmap_array
            final_threshold = threshold
    else:
        processed_array = bitmap_array
        final_threshold = threshold
    
    # é«˜æ•ˆçš„å‘é‡åŒ–ä½æ‰“åŒ…
    h, w = processed_array.shape
    bytes_per_row = (w + 7) // 8
    
    # å‘é‡åŒ–äºŒå€¼åŒ–
    if isinstance(final_threshold, np.ndarray):
        binary_mask = processed_array < final_threshold
    else:
        binary_mask = processed_array < final_threshold
    
    # ä½¿ç”¨NumPyçš„ä½æ“ä½œè¿›è¡Œå¿«é€Ÿæ‰“åŒ…
    out = np.zeros(bytes_per_row * h, dtype=np.uint8)
    
    # é€è¡Œå¤„ç†ï¼Œä½†ä½¿ç”¨å‘é‡åŒ–æ“ä½œ
    for y in range(h):
        row_bits = binary_mask[y, :]
        row_start = y * bytes_per_row
        
        # å¤„ç†å®Œæ•´çš„å­—èŠ‚
        full_bytes = w // 8
        for byte_idx in range(full_bytes):
            bit_start = byte_idx * 8
            bits = row_bits[bit_start:bit_start + 8]
            
            # å‘é‡åŒ–ä½æ“ä½œ
            byte_val = np.sum(bits * (1 << np.arange(7, -1, -1)))
            out[row_start + byte_idx] = byte_val
        
        # å¤„ç†å‰©ä½™çš„ä½
        remaining_bits = w % 8
        if remaining_bits > 0:
            byte_val = 0
            bit_start = full_bytes * 8
            for i in range(remaining_bits):
                if row_bits[bit_start + i]:
                    byte_val |= (1 << (7 - i))
            out[row_start + full_bytes] = byte_val
    
    return bytes(out)


def simple_smooth(bitmap_array, kernel_size=3):
    """
    ç®€å•çš„å¹³æ»‘å¤„ç†ï¼Œä¸ä¾èµ–scipy
    """
    if bitmap_array.size == 0 or kernel_size < 3:
        return bitmap_array
    
    h, w = bitmap_array.shape
    smoothed = bitmap_array.astype(np.float32)
    result = np.zeros_like(smoothed)
    
    # ç®€å•çš„å‡å€¼æ»¤æ³¢
    pad = kernel_size // 2
    for y in range(h):
        for x in range(w):
            # è®¡ç®—é‚»åŸŸå¹³å‡å€¼
            neighbor_sum = 0
            neighbor_count = 0
            
            for dy in range(-pad, pad + 1):
                for dx in range(-pad, pad + 1):
                    ny, nx = y + dy, x + dx
                    if 0 <= ny < h and 0 <= nx < w:
                        # ä½¿ç”¨é«˜æ–¯æƒé‡
                        weight = np.exp(-(dx*dx + dy*dy) / (2 * 0.8 * 0.8))
                        neighbor_sum += smoothed[ny, nx] * weight
                        neighbor_count += weight
            
            if neighbor_count > 0:
                result[y, x] = neighbor_sum / neighbor_count
            else:
                result[y, x] = smoothed[y, x]
    
    return np.clip(result, 0, 255).astype(np.uint8)


def process_char(face, font_height, ch, ascender, white_threshold, enable_smoothing=True, timing_stats=None, keep_placeholder=False):
    """
    å¤„ç†å•ä¸ªå­—ç¬¦ï¼Œç”Ÿæˆ1ä½ä½å›¾æ•°æ®
    enable_smoothing: æ˜¯å¦å¯ç”¨è¾¹ç¼˜å¹³æ»‘å¤„ç†
    timing_stats: æ€§èƒ½ç»Ÿè®¡å­—å…¸ï¼Œç”¨äºè®°å½•è€—æ—¶
    è¿”å›: (char_data, replacement_info)
    """
    start_time = time.time()
    codepoint = ord(ch)
    replacement_info = None
    
    # è·³è¿‡æ§åˆ¶å­—ç¬¦å’ŒBOM
    if codepoint < 0x20 or codepoint == 0xFEFF:
        return (codepoint, 0, 0, 0, 0, 0, b''), replacement_info

    render_start = time.time()
    
    # å°è¯•åŠ è½½å­—ç¬¦å­—å½¢
    glyph_index = face.get_char_index(codepoint)
    if glyph_index == 0:
        # å­—å½¢ç¼ºå¤±
        replacement_info = ch
        if not keep_placeholder:
            # é»˜è®¤è¡Œä¸ºï¼šè·³è¿‡ç¼ºå¤±å­—å½¢ï¼ˆä¸äº§ç”Ÿæ¡ç›®ï¼‰
            return (None, replacement_info)

        # å°è¯•ä½¿ç”¨æ›¿æ¢å­—ç¬¦ U+25A1 (â–¡)
        replacement_index = face.get_char_index(0x25A1)
        if replacement_index == 0:
            # å¦‚æœå­—ä½“ä¹Ÿä¸åŒ…å« U+25A1ï¼Œåˆ™ç”Ÿæˆå†…ç½®æ–¹æ¡†å ä½ä½å›¾
            # æ–¹æ¡†å¤§å°ä»¥ font_height ä¸ºåŸºå‡†
            bw = font_height
            bh = font_height
            box = np.full((bh, bw), 255, dtype=np.uint8)
            border = max(1, font_height // 12)
            box[0:border, :] = 0
            box[-border:, :] = 0
            box[:, 0:border] = 0
            box[:, -border:] = 0
            bmp = pack_1bit_bitmap(box, threshold=white_threshold, enable_smoothing=False)

            # ä½¿ç”¨åˆç†çš„ advance/offset å€¼ï¼Œä¿è¯åœ¨è®¾å¤‡ä¸Šèƒ½æ­£å¸¸æ˜¾ç¤º
            advance_width = int(font_height * 0.6)
            x_offset = 0
            y_offset = ascender - (font_height // 2)
            return (codepoint, bw, bh, advance_width, x_offset, y_offset, bmp), replacement_info
        else:
            # ä½¿ç”¨å­—ä½“ä¸­çš„æ–¹å—å­—å½¢
            face.load_char(0x25A1, freetype.FT_LOAD_RENDER | freetype.FT_LOAD_TARGET_NORMAL)
    else:
        face.load_char(codepoint, freetype.FT_LOAD_RENDER | freetype.FT_LOAD_TARGET_NORMAL)

    bitmap = face.glyph.bitmap
    metrics = face.glyph.metrics

    render_time = time.time() - render_start

    # æ£€æŸ¥ä½å›¾æ˜¯å¦æœ‰æ•ˆ
    if bitmap.buffer and bitmap.width > 0 and bitmap.rows > 0:
        bitmap_array = np.array(bitmap.buffer, dtype=np.uint8).reshape((bitmap.rows, bitmap.width))
    else:
        bitmap_array = np.zeros((0, 0), dtype=np.uint8)

    # å¦‚æœæ²¡æœ‰ä½å›¾æ•°æ®ï¼Œè¿”å›ç©ºå­—ç¬¦
    if bitmap_array.size == 0:
        advance_width = metrics.horiAdvance >> 6
        x_offset = metrics.horiBearingX >> 6
        y_offset = ascender - face.glyph.bitmap_top
        return (codepoint, 0, 0, advance_width, x_offset, y_offset, b''), replacement_info

    # åŸºäºç™½è‰²é˜ˆå€¼è¯†åˆ«éç©ºåŒºåŸŸï¼ˆFreeType: 0=é»‘, 255=ç™½ï¼‰
    # ä½äº(255-white_threshold)çš„åƒç´ è¢«è®¤ä¸ºæ˜¯æœ‰å†…å®¹çš„
    content_threshold = 255 - white_threshold
    non_empty_rows = np.any(bitmap_array < content_threshold, axis=1)
    non_empty_cols = np.any(bitmap_array < content_threshold, axis=0)

    # å¦‚æœæ²¡æœ‰å†…å®¹ï¼Œè¿”å›ç©ºå­—ç¬¦
    if not (np.any(non_empty_rows) and np.any(non_empty_cols)):
        advance_width = metrics.horiAdvance >> 6
        x_offset = metrics.horiBearingX >> 6
        y_offset = ascender - face.glyph.bitmap_top
        return (codepoint, 0, 0, advance_width, x_offset, y_offset, b''), replacement_info

    # è£å‰ªåˆ°å®é™…å†…å®¹åŒºåŸŸ
    crop_start = time.time()
    min_y = np.argmax(non_empty_rows)
    max_y = bitmap.rows - 1 - np.argmax(non_empty_rows[::-1])
    min_x = np.argmax(non_empty_cols)
    max_x = bitmap.width - 1 - np.argmax(non_empty_cols[::-1])

    cropped = bitmap_array[min_y:max_y + 1, min_x:max_x + 1]
    crop_time = time.time() - crop_start

    # ä½¿ç”¨å¸¦è¾¹ç¼˜å¹³æ»‘çš„äºŒå€¼åŒ–
    process_start = time.time()
    bitmap_data = pack_1bit_bitmap(cropped, threshold=white_threshold, enable_smoothing=enable_smoothing)
    process_time = time.time() - process_start

    # è®¡ç®—å­—ç¬¦åº¦é‡ä¿¡æ¯
    advance_width = metrics.horiAdvance >> 6
    x_offset = (metrics.horiBearingX >> 6) + min_x
    y_offset = (ascender - face.glyph.bitmap_top) + min_y

    total_time = time.time() - start_time
    
    # è®°å½•æ€§èƒ½ç»Ÿè®¡
    if timing_stats is not None:
        timing_stats['render_time'] += render_time
        timing_stats['crop_time'] += crop_time
        timing_stats['process_time'] += process_time
        timing_stats['total_time'] += total_time
        timing_stats['count'] += 1

    return (codepoint, cropped.shape[1], cropped.shape[0], advance_width, x_offset, y_offset, bitmap_data), replacement_info


def can_render_character(face, char):
    """
    æ£€æŸ¥å­—ç¬¦æ˜¯å¦å¯ä»¥è¢«å­—ä½“æ­£ç¡®æ¸²æŸ“
    ä½¿ç”¨å®é™…æ¸²æŸ“æµ‹è¯•ï¼Œæ¯”get_char_index()æ›´å‡†ç¡®
    """
    try:
        # å°è¯•åŠ è½½å¹¶æ¸²æŸ“å­—ç¬¦
        face.load_char(char, freetype.FT_LOAD_RENDER)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä½å›¾å†…å®¹
        bitmap = face.glyph.bitmap
        if bitmap.width == 0 or bitmap.rows == 0:
            return False
            
        # æ£€æŸ¥ä½å›¾æ˜¯å¦æœ‰éé›¶åƒç´ 
        if hasattr(bitmap, 'buffer') and bitmap.buffer:
            buffer_data = np.array(bitmap.buffer, dtype=np.uint8)
            if len(buffer_data) > 0 and np.any(buffer_data > 0):
                return True
        
        return False
        
    except Exception:
        return False

def build_charset(include_gbk=True, include_traditional=True, include_japanese=False, face=None):
    """
    æ„å»ºå­—ç¬¦é›†ï¼ŒåŒ…å«ASCIIå’Œå¯é€‰çš„ä¸­æ—¥éŸ©å­—ç¬¦
    include_gbk: åŒ…å«GBKç®€ä½“ä¸­æ–‡å­—ç¬¦é›†ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
    include_traditional: åŒ…å«ç¹ä½“ä¸­æ–‡å­—ç¬¦é›†ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
    include_japanese: åŒ…å«æ—¥æ–‡å­—ç¬¦é›†
    face: FreeTypeå­—ä½“faceå¯¹è±¡ï¼ˆä¿ç•™å‚æ•°å…¼å®¹æ€§ï¼Œä½†ä¸ä½¿ç”¨ï¼‰
    """
    # åŸºç¡€ASCIIå¯æ‰“å°å­—ç¬¦ (0x20-0x7E)
    chars = [chr(c) for c in range(0x20, 0x7F)]
    
    if include_gbk:
        # GBKå­—ç¬¦é›†ï¼ˆç®€ä½“ä¸­æ–‡ï¼‰
        print("æ­£åœ¨æ„å»ºGBKç®€ä½“ä¸­æ–‡å­—ç¬¦é›†...")
        gbk_chars = 0
        for lead in range(0x81, 0xFF):
            for trail in chain(range(0x40, 0x7F), range(0x80, 0xFE + 1)):
                try:
                    ch = bytes([lead, trail]).decode('gbk')
                    chars.append(ch)
                    gbk_chars += 1
                except UnicodeDecodeError:
                    # å¿½ç•¥æ— æ•ˆçš„GBKç¼–ç 
                    pass
        print(f"  GBKç®€ä½“ä¸­æ–‡å­—ç¬¦: {gbk_chars} ä¸ª")
    
    if include_traditional:
        # ç¹ä½“ä¸­æ–‡å­—ç¬¦é›†ï¼ˆBig5ç¼–ç èŒƒå›´ + å¸¸ç”¨ç¹ä½“å­—UnicodeèŒƒå›´ï¼‰
        print("æ­£åœ¨æ„å»ºç¹ä½“ä¸­æ–‡å­—ç¬¦é›†...")
        
        big5_chars = 0
        unicode_chars = 0
        
        # Big5ç¼–ç èŒƒå›´ (ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„Big5ç¼–ç èŒƒå›´)
        for lead in range(0xA1, 0xFE + 1):
            for trail in chain(range(0x40, 0x7E + 1), range(0xA1, 0xFE + 1)):
                try:
                    ch = bytes([lead, trail]).decode('big5')
                    chars.append(ch)
                    big5_chars += 1
                except UnicodeDecodeError:
                    pass
        
        print(f"  Big5ç¼–ç å­—ç¬¦: {big5_chars} ä¸ª")
        
        # Unicodeç¹ä½“ä¸­æ–‡å¸¸ç”¨èŒƒå›´
        traditional_ranges = [
            (0x4E00, 0x9FFF),  # CJKç»Ÿä¸€æ±‰å­—
            (0x3400, 0x4DBF),  # CJKæ‰©å±•A
            (0xF900, 0xFAFF),  # CJKå…¼å®¹æ±‰å­—
        ]
        
        for start, end in traditional_ranges:
            for codepoint in range(start, end + 1):
                try:
                    ch = chr(codepoint)
                    # æ£€æŸ¥å­—ç¬¦æ˜¯å¦å¯æ‰“å°ä¸”ä¸æ˜¯ç©ºç™½å­—ç¬¦
                    if ch.isprintable() and not ch.isspace():
                        chars.append(ch)
                        unicode_chars += 1
                except ValueError:
                    pass
        
        print(f"  UnicodeèŒƒå›´å­—ç¬¦: {unicode_chars} ä¸ª")
        print(f"  ç¹ä½“ä¸­æ–‡å­—ç¬¦æ€»è®¡: {big5_chars + unicode_chars} ä¸ª")
    
    if include_japanese:
        # æ—¥æ–‡å­—ç¬¦é›†
        print("æ­£åœ¨æ„å»ºæ—¥æ–‡å­—ç¬¦é›†...")
        
        # æ—¥æ–‡å­—ç¬¦UnicodeèŒƒå›´
        japanese_ranges = [
            (0x3040, 0x309F),  # å¹³å‡å
            (0x30A0, 0x30FF),  # ç‰‡å‡å
            (0x4E00, 0x9FAF),  # æ±‰å­—ï¼ˆæ—¥æ–‡ä¸­ä½¿ç”¨çš„ï¼‰
            (0x3400, 0x4DBF),  # CJKæ‰©å±•Aï¼ˆæ—¥æ–‡ä¸­ä½¿ç”¨çš„ï¼‰
            (0xFF65, 0xFF9F),  # åŠè§’ç‰‡å‡å
            (0x31F0, 0x31FF),  # ç‰‡å‡åæ‹¼éŸ³æ‰©å±•
            (0x3200, 0x32FF),  # å¸¦åœˆCJKå­—æ¯å’Œæœˆä»½
            (0x3300, 0x33FF),  # CJKå…¼å®¹
        ]
        
        for start, end in japanese_ranges:
            for codepoint in range(start, end + 1):
                try:
                    ch = chr(codepoint)
                    if ch.isprintable():
                        chars.append(ch)
                except ValueError:
                    pass
    
    # æ·»åŠ ç‰¹æ®Šå­—ç¬¦
    special_chars = [
        '\u2022',  # é¡¹ç›®ç¬¦å· â€¢
        '\u25A1',  # ç™½è‰²æ–¹å— â–¡ (ç”¨ä½œæ›¿æ¢å­—ç¬¦)
        '\uFEFF',  # BOM
    ]
    chars.extend(special_chars)
    
    # å»é‡å¹¶æŒ‰Unicodeç ç‚¹æ’åº
    chars = sorted(set(chars), key=lambda c: ord(c))
    
    # æµ‹è¯•å¸¸è§ç¹ä½“å­—æ˜¯å¦åŒ…å«ï¼ˆè°ƒè¯•ç”¨ï¼‰
    if include_traditional:
        # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„è¯—å¥ä½œä¸ºæµ‹è¯•ç”¨ä¾‹ï¼ˆå»æ‰æ ‡ç‚¹ï¼‰:
        # "æ°£è’¸é›²å¤¢æ¾¤ï¼Œæ³¢æ’¼å¶½é™½åŸ" -> å»æ‰æ ‡ç‚¹: æ°£è’¸é›²å¤¢æ¾¤æ³¢æ’¼å¶½é™½åŸ
        test_traditional = list('æ°£è’¸é›²å¤¢æ¾¤æ³¢æ’¼å¶½é™½åŸ')
        found_traditional = [ch for ch in test_traditional if ch in chars]
        print(f"  å¸¸è§ç¹ä½“å­—æµ‹è¯•: {len(found_traditional)}/{len(test_traditional)} ä¸ªå­—ç¬¦è¢«åŒ…å«")
        print(f"  åŒ…å«çš„å­—ç¬¦: {found_traditional}")
        if len(found_traditional) < len(test_traditional):
            missing = [ch for ch in test_traditional if ch not in chars]
            print(f"  ç¼ºå¤±çš„ç¹ä½“å­—: {missing}")
            for missing_char in missing:
                print(f"    '{missing_char}' (U+{ord(missing_char):04X})")
    
    return chars


def render_demo_image(face, text, font_height, scale, out_path, white_threshold=80, enable_smoothing=True):
    """
    ä½¿ç”¨ FreeType æ¸²æŸ“ç»™å®šæ–‡æœ¬å¹¶ä¿å­˜ä¸º demo PNGã€‚æ–‡æœ¬å¯ä»¥åŒ…å«æ¢è¡Œã€‚
    è¿™ä¸ªå‡½æ•°å¤ç”¨ process_char çš„ä¸€äº›é€»è¾‘ï¼Œä½†ä¸ºäº†é€Ÿåº¦ä¼šç›´æ¥æ¸²æŸ“ glyph bitmap å¹¶æŒ‰è¡Œæ‹¼æ¥ã€‚
    """
    if not HAS_PIL:
        print("âš ï¸ Pillow æœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆ demo å›¾ç‰‡ã€‚è¯·è¿è¡Œ: python -m pip install pillow")
        return False

    lines = text.split("\\n")

    # ä½¿ç”¨ç©ºæ ¼å®½åº¦ä½œä¸ºå­—ç¬¦é—´éš”ï¼ˆç¡®ä¿å­—ç¬¦ä¹‹é—´ç©ºå‡ºä¸€ä¸ªç©ºæ ¼ï¼‰
    face.load_char(' ', freetype.FT_LOAD_RENDER | freetype.FT_LOAD_TARGET_NORMAL)
    space_adv = face.glyph.advance.x >> 6

    # å…ˆæµ‹é‡æ¯ä¸€è¡Œçš„åƒç´ å°ºå¯¸
    ascender = face.size.ascender >> 6
    max_w = 0
    total_h = 0
    line_metrics = []
    for line in lines:
        lw = 0
        lh = 0
        for ci, ch in enumerate(line):
            face.load_char(ch, freetype.FT_LOAD_RENDER | freetype.FT_LOAD_TARGET_NORMAL)
            bmp = face.glyph.bitmap
            adv = face.glyph.advance.x >> 6
            w = bmp.width
            h = bmp.rows
            lw += adv
            # åœ¨å­—ç¬¦ä¹‹é—´åŠ å…¥ä¸€ä¸ªç©ºæ ¼å®½åº¦ï¼ˆä½†ä¸åœ¨æœ€åä¸€ä¸ªå­—ç¬¦ååŠ å…¥ï¼‰
            if ci != len(line) - 1:
                lw += space_adv
            lh = max(lh, h)
        line_metrics.append((lw, lh))
        max_w = max(max_w, lw)
        total_h += lh if lh > 0 else font_height

    if max_w == 0:
        max_w = 200
    if total_h == 0:
        total_h = font_height * len(lines)

    # margin: ç•™å‡ºä¸€ä¸ªå­—ç¬¦çš„ marginï¼ˆæŒ‰ font_height è®¡ç®—ï¼‰ï¼Œä¹˜ä»¥ scale
    margin = font_height * scale

    img_w = int(max_w * scale + margin * 2)
    img_h = int(total_h * scale + margin * 2)

    img = Image.new('L', (img_w, img_h), color=255)

    y = margin
    for li, line in enumerate(lines):
        x = margin
        for ch in line:
            face.load_char(ch, freetype.FT_LOAD_RENDER | freetype.FT_LOAD_TARGET_NORMAL)
            bmp = face.glyph.bitmap
            w = bmp.width
            h = bmp.rows
            buffer = bmp.buffer
            if buffer and w > 0 and h > 0:
                arr = np.array(buffer, dtype=np.uint8).reshape((h, w))
                # ç›´æ¥ä½¿ç”¨é˜ˆå€¼ç”ŸæˆäºŒå€¼æ©ç ï¼Œç¡®ä¿é»‘è‰²åƒç´ ä¸ºå­—ä½“ï¼ˆTrue = glyphï¼‰
                binary_mask = arr < (255 - white_threshold)

                # ä½¿ç”¨ NumPy æ„é€ ç°åº¦çŸ©é˜µï¼šglyph = 0 (é»‘), èƒŒæ™¯ = 255 (ç™½)
                tile_data = np.where(binary_mask, 0, 255).astype(np.uint8)
                tile = Image.fromarray(tile_data, mode='L')

                if scale != 1:
                    tile = tile.resize((w * scale, h * scale), resample=Image.NEAREST)
                img.paste(tile, (int(x), int(y)))

            adv = face.glyph.advance.x >> 6
            # æ¯ä¸ªå­—ç¬¦åå¢åŠ ç©ºæ ¼å®½åº¦ä½œä¸ºåˆ†éš”
            x += max(adv * scale, 1)
            x += space_adv * scale

        y += max(line_metrics[li][1] * scale, font_height * scale)

    img = img.convert('L')
    img.save(out_path)
    print(f"âœ… Demo å›¾ç‰‡å·²ä¿å­˜: {out_path}")
    return True


def read_bin_font(bin_path):
    """
    è¯»å–ç”Ÿæˆçš„ .bin å­—ä½“æ–‡ä»¶ï¼Œè¿”å›å…ƒæ•°æ®å’Œå­—ç¬¦è¡¨ï¼ˆmap: codepoint -> entry dictï¼‰
    Entry fields: advance, bw, bh, xo, yo, bitmap_bytes
    """
    if not os.path.isfile(bin_path):
        raise FileNotFoundError(bin_path)

    with open(bin_path, 'rb') as f:
        header = f.read(6)
        if len(header) < 6:
            raise ValueError('Invalid bin file')
        char_count, font_height, version = struct.unpack('<IBB', header)
        family = f.read(64).split(b'\0', 1)[0].decode('utf-8', errors='ignore')
        style = f.read(64).split(b'\0', 1)[0].decode('utf-8', errors='ignore')

        entry_size = 20
        entries = {}
        entries_raw = []
        for i in range(char_count):
            data = f.read(entry_size)
            if len(data) != entry_size:
                raise ValueError('Invalid entry in bin file')
            cp, adv, bw, bh, xo, yo, off, length, _ = struct.unpack('<HHBBbbIII', data)
            entries_raw.append((cp, adv, bw, bh, xo, yo, off, length))

        # è¯»å–ä½å›¾æ•°æ®
        for cp, adv, bw, bh, xo, yo, off, length in entries_raw:
            f.seek(off)
            bmp = f.read(length)
            entries[cp] = {
                'advance': int(adv),
                'bw': int(bw),
                'bh': int(bh),
                'xo': int(xo),
                'yo': int(yo),
                'bitmap': bmp
            }

    return {
        'char_count': int(char_count),
        'font_height': int(font_height),
        'version': int(version),
        'family': family,
        'style': style,
        'entries': entries
    }


def unpack_1bit_bitmap(bmp_bytes, bw, bh):
    """
    å°† .bin ä¸­æ‰“åŒ…çš„ 1-bit ä½å›¾è§£åŒ…æˆ uint8 ç°åº¦çŸ©é˜µ (0=black, 255=white)
    """
    if bw == 0 or bh == 0:
        return np.zeros((0, 0), dtype=np.uint8)

    bytes_per_row = (bw + 7) // 8
    expected = bytes_per_row * bh
    if len(bmp_bytes) < expected:
        # å¡«å……ç¼ºå¤±æ•°æ®
        #bmp_bytes = bmp_bytes.ljust(expected, b'\x00')
        bmp_bytes = bmp_bytes.ljust(expected, b'\xff')

    #arr = np.full((bh, bw), 255, dtype=np.uint8)
    arr = np.full((bh, bw), 0, dtype=np.uint8)
    view = memoryview(bmp_bytes)
    for y in range(bh):
        row = view[y * bytes_per_row:(y + 1) * bytes_per_row]
        for bx in range(bytes_per_row):
            byte = row[bx]
            for bit in range(8):
                x = bx * 8 + bit
                if x >= bw:
                    break
                # é«˜ä½å…ˆè¡Œ
                if byte & (1 << (7 - bit)):
                    #arr[y, x] = 0
                    arr[y, x] = 255

    return arr


def render_demo_from_bin(bin_path, text, scale, out_path):
    """
    ä» .bin æ–‡ä»¶å¿«é€Ÿæ¸²æŸ“ demo å›¾ç‰‡ï¼ˆwhite background, black glyphsï¼‰ï¼Œä½¿ç”¨ bin å†…çš„ advance/bitmapã€‚
    ç®€åŒ–å‚ç›´å¯¹é½ï¼šæ¯è¡Œä»¥æœ€å¤§å­—å½¢é«˜åº¦ä¸ºè¡Œé«˜ï¼Œå­—å½¢åº•éƒ¨å¯¹é½ã€‚
    """
    if not HAS_PIL:
        print("âš ï¸ Pillow æœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆ demo å›¾ç‰‡ã€‚è¯·è¿è¡Œ: python -m pip install pillow")
        return False

    info = read_bin_font(bin_path)
    entries = info['entries']
    font_h = info['font_height']

    lines = text.split("\n")

    # ç©ºæ ¼ advance
    space_adv = entries.get(ord(' '), {}).get('advance', max(1, font_h // 4))

    # è®¡ç®—æ¯è¡Œåƒç´ å®½åº¦å’Œè¡Œé«˜
    max_w = 0
    total_h = 0
    line_metrics = []
    for line in lines:
        lw = 0
        lh = 0
        for i, ch in enumerate(line):
            cp = ord(ch)
            ent = entries.get(cp)
            if ent is None:
                # å°è¯•æ›¿æ¢æ–¹å—
                ent = entries.get(0x25A1)
            if ent is None:
                adv = font_h // 2
                bw = 0
                bh = font_h
            else:
                adv = ent['advance']
                bw = ent['bw']
                bh = ent['bh']

            lw += adv
            if i != len(line) - 1:
                lw += space_adv
            lh = max(lh, bh if bh > 0 else font_h)

        line_metrics.append((lw, lh))
        max_w = max(max_w, lw)
        total_h += lh if lh > 0 else font_h

    if max_w == 0:
        max_w = 200
    if total_h == 0:
        total_h = font_h * len(lines)

    margin = int(font_h * scale)
    img_w = int(max_w * scale + margin * 2)
    img_h = int(total_h * scale + margin * 2)

    img = Image.new('L', (img_w, img_h), color=255)

    y = margin
    for li, line in enumerate(lines):
        x = margin
        lh = line_metrics[li][1]
        for ch in line:
            cp = ord(ch)
            ent = entries.get(cp)
            if ent is None:
                ent = entries.get(0x25A1)
            if ent is None:
                # è·³è¿‡ä¸å¯ç”¨å­—ç¬¦
                adv = font_h // 2
                x += max(int(adv * scale), 1)
                x += int(space_adv * scale)
                continue

            bw = ent['bw']
            bh = ent['bh']
            bmp = ent['bitmap']

            if bw > 0 and bh > 0 and bmp:
                tile_arr = unpack_1bit_bitmap(bmp, bw, bh)
                # tile_arr: 0=black,255=white
                tile = Image.fromarray(tile_arr, mode='L')
                if scale != 1:
                    tile = tile.resize((int(bw * scale), int(bh * scale)), resample=Image.NEAREST)

                # å‚ç›´åº•éƒ¨å¯¹é½
                ty = int(y + (lh - bh) * scale)
                img.paste(tile, (int(x), ty))

            adv = ent['advance']
            x += max(int(adv * scale), 1)
            x += int(space_adv * scale)

        y += max(int(lh * scale), int(font_h * scale))

    img.save(out_path)
    print(f"âœ… Demo å›¾ç‰‡å·²ä¿å­˜ (from .bin): {out_path}")
    return True


def generate_binary_font(char_data, output_path, font_height, format_version=2, family_name="", style_name=""):
    """
    ç”ŸæˆäºŒè¿›åˆ¶å­—ä½“æ–‡ä»¶
    """
    char_count = len(char_data)
    header_size = 4 + 1 + 1 + 64 + 64  # uint32 count + uint8 font_size + uint8 version + char[64] family + char[64] style
    entry_size = 20  # æ¯ä¸ªå­—ç¬¦æ¡ç›®çš„å­—èŠ‚æ•°
    
    # è®¡ç®—æ•°æ®åç§»
    current_offset = header_size + char_count * entry_size

    bin_content = bytearray()
    entries = []
    bitmap_data = bytearray()

    # å†™å…¥æ–‡ä»¶å¤´
    bin_content.extend(struct.pack('<IBB', char_count, font_height, format_version))
    
    # UTF-8 å®‰å…¨æˆªæ–­ï¼šç¡®ä¿ä¸ä¼šåœ¨å¤šå­—èŠ‚å­—ç¬¦ä¸­é—´æˆªæ–­
    def utf8_truncate(s, max_bytes):
        b = s.encode('utf-8')
        if len(b) <= max_bytes:
            return b
        # å®‰å…¨çš„å›é€€ï¼šå°è¯•è§£ç ï¼Œè‹¥å¤±è´¥åˆ™é€å­—èŠ‚å›é€€ï¼Œç›´åˆ°ä¸ºåˆæ³• UTF-8 æˆ–ä¸ºç©º
        cut = b[:max_bytes]
        while cut:
            try:
                cut.decode('utf-8')
                return cut
            except UnicodeDecodeError:
                # ä¸¢å¼ƒæœ€åä¸€ä¸ªå­—èŠ‚ç»§ç»­å°è¯•
                cut = cut[:-1]
        return b''

    # å†™å…¥å­—ä½“æ—åï¼ˆ64å­—èŠ‚ï¼ŒUTF-8ç¼–ç ï¼Œnullç»“å°¾ï¼‰
    family_bytes = utf8_truncate(family_name, 63)
    family_padded = family_bytes + b'\0' * (64 - len(family_bytes))
    bin_content.extend(family_padded)
    
    # å†™å…¥å­—ä½“æ ·å¼åï¼ˆ64å­—èŠ‚ï¼ŒUTF-8ç¼–ç ï¼Œnullç»“å°¾ï¼‰
    style_bytes = utf8_truncate(style_name, 63)
    style_padded = style_bytes + b'\0' * (64 - len(style_bytes))
    bin_content.extend(style_padded)

    # å¤„ç†æ¯ä¸ªå­—ç¬¦
    for cp, bw, bh, w, xo, yo, bmp in char_data:
        # é™åˆ¶åç§»é‡åˆ°int8èŒƒå›´ (-128 åˆ° 127)
        xo = int(np.clip(xo, -128, 127))
        yo = int(np.clip(yo, -128, 127))
        
        # æ‰“åŒ…å­—ç¬¦æ¡ç›® (20å­—èŠ‚)
        entry = struct.pack('<HHBBbbIII',
                            cp & 0xFFFF,      # å­—ç¬¦ç ç‚¹ (2å­—èŠ‚)
                            w & 0xFFFF,       # å­—ç¬¦å®½åº¦ (2å­—èŠ‚)
                            bw & 0xFF,        # ä½å›¾å®½åº¦ (1å­—èŠ‚)
                            bh & 0xFF,        # ä½å›¾é«˜åº¦ (1å­—èŠ‚)
                            xo,               # Xåç§» (1å­—èŠ‚)
                            yo,               # Yåç§» (1å­—èŠ‚)
                            current_offset,   # ä½å›¾æ•°æ®åç§» (4å­—èŠ‚)
                            len(bmp),         # ä½å›¾æ•°æ®é•¿åº¦ (4å­—èŠ‚)
                            0)                # ä¿ç•™å­—æ®µ (4å­—èŠ‚)
        entries.append(entry)
        bitmap_data.extend(bmp)
        current_offset += len(bmp)

    # ç»„è£…æœ€ç»ˆæ–‡ä»¶
    for entry in entries:
        bin_content.extend(entry)
    bin_content.extend(bitmap_data)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
    
    # å†™å…¥æ–‡ä»¶
    with open(output_path, 'wb') as f:
        f.write(bin_content)

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    char_table_size = len(entries) * entry_size
    bitmap_size = len(bitmap_data)
    total_size = header_size + char_table_size + bitmap_size
    
    print(f"\nğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
    print(f"  Header: {header_size} bytes")
    print(f"  å­—ç¬¦è¡¨: {char_table_size} bytes ({char_table_size/total_size:.1%})")
    print(f"  ä½å›¾æ•°æ®: {bitmap_size} bytes ({bitmap_size/total_size:.1%})")
    print(f"  æ€»è®¡: {total_size} bytes")
    
    return output_path


def main():
    """
    ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶ç”Ÿæˆ1ä½å­—ä½“æ–‡ä»¶
    """
    parser = argparse.ArgumentParser(
        description="ç”Ÿæˆ1ä½æ‰“åŒ…å­—ä½“æ–‡ä»¶ (.bin)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # é»˜è®¤ï¼šç®€ä½“+ç¹ä½“ä¸­æ–‡
  python generate_1bit_font_bin.py --size 32 --white 80 font.otf output.bin
  
  # ä»…ç®€ä½“ä¸­æ–‡
  python generate_1bit_font_bin.py --no-traditional font.ttf output.bin
  
  # ä»…ç¹ä½“ä¸­æ–‡
  python generate_1bit_font_bin.py --no-gbk font.ttf output.bin
  
  # ç®€ä½“+ç¹ä½“+æ—¥æ–‡å…¨é›†
  python generate_1bit_font_bin.py --japanese font.ttf output.bin
  
  # ä»…ASCIIå­—ç¬¦é›†
  python generate_1bit_font_bin.py --ascii-only font.ttf output.bin
        """)
    
    parser.add_argument("font", help="å­—ä½“æ–‡ä»¶è·¯å¾„ (.ttf/.otf)")
    parser.add_argument("out", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (.bin)")
    parser.add_argument("--export-charset", dest='export_charset', default='webapp/extension/assets/charset_default.json',
                       help="å¯é€‰ï¼šå°†æ„å»ºçš„å­—ç¬¦é›†å¯¼å‡ºä¸º JSONï¼Œä¾› webapp ä½¿ç”¨ï¼ˆé»˜è®¤: webapp/extension/assets/charset_default.jsonï¼‰ã€‚è®¾ç½®ä¸ºç©ºå¯ç¦ç”¨æ­¤å¯¼å‡ºã€‚ï¼‰")
    parser.add_argument("--size", type=int, default=32, 
                       help="å­—ä½“åƒç´ é«˜åº¦ (28-42ï¼Œé»˜è®¤32)")
    parser.add_argument("--white", type=int, default=80, 
                       help="ç™½è‰²é˜ˆå€¼ (0-255ï¼Œé»˜è®¤80ï¼Œè¶Šä½è¶Šç»†)")
    parser.add_argument("--no-gbk", action='store_true', 
                       help="ä¸åŒ…å«GBKç®€ä½“ä¸­æ–‡å­—ç¬¦é›†")
    parser.add_argument("--no-traditional", action='store_true',
                       help="ä¸åŒ…å«ç¹ä½“ä¸­æ–‡å­—ç¬¦é›†")
    parser.add_argument("--japanese", action='store_true',
                       help="åŒ…å«æ—¥æ–‡å­—ç¬¦é›†ï¼ˆå¹³å‡åã€ç‰‡å‡åã€æ±‰å­—ï¼‰")
    parser.add_argument("--ascii-only", action='store_true',
                       help="ä»…åŒ…å«ASCIIå­—ç¬¦é›†ï¼Œæ’é™¤æ‰€æœ‰ä¸­æ—¥éŸ©å­—ç¬¦")
    parser.add_argument("--no-smooth", action='store_true',
                       help="ç¦ç”¨è¾¹ç¼˜å¹³æ»‘å¤„ç†")
    parser.add_argument("--fast", action='store_true',
                       help="å¿«é€Ÿæ¨¡å¼ï¼šè·³è¿‡æ‰€æœ‰ä¼˜åŒ–å¤„ç†ä»¥è·å¾—æœ€å¿«é€Ÿåº¦")
    parser.add_argument("--demo", type=str, default=None,
                       help="ç”Ÿæˆ demo å›¾ç‰‡ï¼Œå‚æ•°ä¸ºè¦æ¸²æŸ“çš„å­—ç¬¦(ç›´æ¥å­—ç¬¦ä¸²)æˆ–ä»¥@å¼€å¤´çš„æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ @chars.txt")
    parser.add_argument("--demo-out", type=str, default="demo.png",
                       help="demo å›¾ç‰‡è¾“å‡ºè·¯å¾„ (é»˜è®¤ demo.png)")
    parser.add_argument("--demo-scale", type=int, default=2,
                       help="demo å›¾ç‰‡ç¼©æ”¾å€æ•° (é»˜è®¤ 2)")
    parser.add_argument("--keep-placeholder", action='store_true',
                       help="å½“å­—ä½“ç¼ºå¤±å­—å½¢æ—¶ä¿ç•™å ä½ç¬¦ï¼ˆä½¿ç”¨ U+25A1 æˆ–ç”Ÿæˆæ–¹æ¡†ï¼‰ï¼Œå¦åˆ™é»˜è®¤è·³è¿‡ç¼ºå¤±å­—å½¢")
    parser.add_argument("--gen-cpp", action='store_true',
                       help="ç”Ÿæˆ C++ ä»£ç æ–‡ä»¶ï¼ˆPROGMEMï¼‰ï¼Œå¯ä¸ .bin æ–‡ä»¶ä¸€èµ·ä½¿ç”¨")
    parser.add_argument("--cpp-out", type=str, default=None,
                       help="C++ ä»£ç è¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤ï¼šä¸ .bin æ–‡ä»¶åŒåï¼Œæ‰©å±•åä¸º .cppï¼‰")
    
    args = parser.parse_args()

    # å‚æ•°éªŒè¯
    if not os.path.isfile(args.font):
        print(f"âŒ å­—ä½“æ–‡ä»¶ä¸å­˜åœ¨: {args.font}")
        return 1

    if not (28 <= args.size <= 42):
        print("âŒ å­—ä½“å¤§å°å¿…é¡»åœ¨28-42ä¹‹é—´")
        return 1
        
    if not (0 <= args.white <= 255):
        print("âŒ ç™½è‰²é˜ˆå€¼å¿…é¡»åœ¨0-255ä¹‹é—´")
        return 1

    enable_smoothing = not args.no_smooth and not args.fast

    # æ„å»ºå­—ç¬¦é›†æè¿°
    charset_desc = []
    if args.ascii_only:
        charset_desc.append("ASCII only")
    else:
        if not args.no_gbk:
            charset_desc.append("GBKç®€ä½“")
        if not args.no_traditional:
            charset_desc.append("ç¹ä½“ä¸­æ–‡")
        if args.japanese:
            charset_desc.append("æ—¥æ–‡")
        if not charset_desc:  # å¦‚æœæ‰€æœ‰éƒ½è¢«ç¦ç”¨äº†ï¼Œå›é€€åˆ°ASCII
            charset_desc.append("ASCII only")
    
    # ç¡®å®šè¿è¡Œæ¨¡å¼
    if args.fast:
        mode_desc = "å¿«é€Ÿæ¨¡å¼ï¼ˆæ— ä¼˜åŒ–å¤„ç†ï¼‰"
    elif args.no_smooth:
        mode_desc = "å…³é—­"
    else:
        mode_desc = "å¼€å¯ï¼ˆé«˜æ•ˆæ¨¡å¼ï¼‰"
    
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆå­—ä½“æ–‡ä»¶...")
    print(f"ğŸ“„ è¾“å…¥: {args.font}")
    print(f"ğŸ“ è¾“å‡º: {args.out}")
    print(f"ğŸ“ å¤§å°: {args.size}px")
    print(f"âšª ç™½è‰²é˜ˆå€¼: {args.white}")
    print(f"ğŸˆ³ å­—ç¬¦é›†: {' + '.join(charset_desc)}")
    print(f"âœ¨ è¾¹ç¼˜å¹³æ»‘: {mode_desc}")
    if args.fast:
        print(f"âš¡ ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼Œé¢„è®¡å¯æå‡ 50-70% å¤„ç†é€Ÿåº¦")

    # åˆå§‹åŒ–FreeType
    try:
        face = freetype.Face(args.font)
        face.set_pixel_sizes(0, args.size)
        face.load_char(' ', freetype.FT_LOAD_RENDER)
        ascender = face.size.ascender >> 6
        
        # æå–å­—ä½“åç§°ä¿¡æ¯ï¼šä¼˜å…ˆå°è¯•ä» name è¡¨è¯»å–ï¼ˆæ”¯æŒæœ¬åœ°åŒ–/ä¸­æ–‡ï¼‰ï¼Œå›é€€åˆ° FreeType æä¾›çš„ family_name
        family_name = None
        style_name = None

        # å°è¯•ä½¿ç”¨ fontTools çš„ name è¡¨ï¼ˆæ›´å¯é åœ°æ”¯æŒä¸­æ–‡/æœ¬åœ°åŒ–åç§°ï¼‰
        try:
            from fontTools.ttLib import TTFont
        except Exception:
            # fontTools ä¸å¯ç”¨ï¼Œæç¤ºç”¨æˆ·å®‰è£…ä»¥è·å–æœ¬åœ°åŒ–åå­—
            print("âš ï¸ fontTools æœªå®‰è£…ï¼Œæ— æ³•ä» name è¡¨è¯»å–æœ¬åœ°åŒ–å­—ä½“åã€‚å»ºè®®: python -m pip install fonttools")
            tt = None
        else:
            tt = None
            try:
                tt = TTFont(args.font)
                name_table = tt['name']

                def pick_name(name_ids):
                    # è¿”å›é¦–ä¸ªæœ€åŒ¹é…çš„ name å­—ç¬¦ä¸²ï¼Œä¼˜å…ˆçº§ï¼šlanguageID(ä¸­æ–‡) + platformID(3), platformID 0, then any
                    # name_ids: list of candidate nameIDï¼Œä¾‹å¦‚ [16,1]
                    # collect candidates grouped by (is_chinese, platform_priority, record)
                    candidates = []
                    chinese_langs = {0x0804, 0x0404, 0x0C04}
                    cjk_re = re.compile('[\u4E00-\u9FFF]')
                    for rec in name_table.names:
                        if rec.nameID in name_ids:
                            try:
                                text = rec.toUnicode()
                            except Exception:
                                continue
                            # å°è¯•å®‰å…¨è¯»å– langID
                            lang_id = None
                            try:
                                # éƒ¨åˆ† fontTools è®°å½•æä¾› getLangID()
                                if hasattr(rec, 'getLangID'):
                                    lang_id = rec.getLangID()
                                elif hasattr(rec, 'langID'):
                                    lang_id = rec.langID
                                elif hasattr(rec, 'languageID'):
                                    lang_id = rec.languageID
                            except Exception:
                                lang_id = None

                            # å¦‚æœæ–‡æœ¬æœ¬èº«åŒ…å« CJK å­—ç¬¦ï¼Œåˆ™ä¼˜å…ˆ
                            contains_cjk = bool(cjk_re.search(text))
                            is_chinese = contains_cjk or ((lang_id in chinese_langs) if lang_id is not None else False)
                            # platform priority: Windows(3) highest, then Unicode(0), then others
                            plat_prio = 2 if getattr(rec, 'platformID', None) == 3 else (1 if getattr(rec, 'platformID', None) == 0 else 0)
                            candidates.append((is_chinese, plat_prio, getattr(rec, 'platformID', 999), text))

                    # sort by chinese first, then platform priority, then platformID
                    if not candidates:
                        return None
                    candidates.sort(key=lambda x: (0 if x[0] else 1, -x[1], x[2]))
                    return candidates[0][3]

                # é¦–å…ˆå°è¯• typographic family/style (nameID 16/17)ï¼Œå†å›é€€åˆ° nameID 1/2
                family_name = pick_name([16, 1])
                style_name = pick_name([17, 2])
                # å°è¯•è¯»å– Full name (nameID 4)ï¼Œç”¨äºè¯Šæ–­/æ˜¾ç¤ºå®Œæ•´å­—ä½“å
                try:
                    full_name = pick_name([4])
                except Exception:
                    full_name = None
            except Exception:
                family_name = None
                style_name = None

        # å¦‚æœæ²¡æœ‰é€šè¿‡ fontTools è·å–åˆ°ï¼Œå›é€€åˆ° FreeType çš„å­—æ®µ
        family_source = None
        style_source = None
        if not family_name:
            # face.family_name may be bytes or str depending on FreeType binding/version
            if getattr(face, 'family_name', None):
                if isinstance(face.family_name, bytes):
                    try:
                        family_name = face.family_name.decode('utf-8', errors='ignore')
                    except Exception:
                        family_name = str(face.family_name)
                else:
                    family_name = str(face.family_name)
            else:
                family_name = "Unknown"
            family_source = 'freetype'
        else:
            family_source = 'name_table'
        if not style_name:
            # face.style_name may be bytes or str depending on FreeType binding/version
            if getattr(face, 'style_name', None):
                if isinstance(face.style_name, bytes):
                    try:
                        style_name = face.style_name.decode('utf-8', errors='ignore')
                    except Exception:
                        style_name = str(face.style_name)
                else:
                    style_name = str(face.style_name)
            else:
                style_name = "Regular"
            style_source = 'freetype'
        else:
            style_source = 'name_table'

        # Log æ¸…æ™°çš„è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ¥æºã€Unicode å­—ç¬¦ä¸²åŠ UTF-8 å­—èŠ‚ä¿¡æ¯ï¼ˆä¾¿äºç¡®è®¤ä¸­æ–‡æ˜¯å¦å®Œæ•´ï¼‰
        try:
            family_bytes_preview = family_name.encode('utf-8')
        except Exception:
            family_bytes_preview = b''
        try:
            style_bytes_preview = style_name.encode('utf-8')
        except Exception:
            style_bytes_preview = b''
        # full_name å¯èƒ½æ¥è‡ª name tableï¼Œç¡®ä¿å­˜åœ¨å¹¶å‡†å¤‡ bytes é¢„è§ˆ
        try:
            full_bytes_preview = full_name.encode('utf-8') if ('full_name' in locals() and full_name) else b''
        except Exception:
            full_bytes_preview = b''

        print(f"ğŸ”¤ å­—ä½“æ—å ({family_source}): {family_name}")
        print(f"   UTF-8 bytes (len={len(family_bytes_preview)}): {family_bytes_preview}")
        print(f"ğŸ¨ å­—ä½“æ ·å¼ ({style_source}): {style_name}")
        print(f"   UTF-8 bytes (len={len(style_bytes_preview)}): {style_bytes_preview}")
        if 'full_name' in locals() and full_name:
            print(f"ğŸ“ Full name (nameID=4): {full_name}")
            print(f"   UTF-8 bytes (len={len(full_bytes_preview)}): {full_bytes_preview}")
        
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½å­—ä½“æ–‡ä»¶: {e}")
        return 1

    # æ„å»ºå­—ç¬¦é›†
    print("\nğŸ“‹ æ„å»ºå­—ç¬¦é›†...")
    chars = build_charset(
        include_gbk=not args.no_gbk and not args.ascii_only,
        include_traditional=not args.no_traditional and not args.ascii_only,
        include_japanese=args.japanese and not args.ascii_only,
        face=face
    )
    total_chars = len(chars)
    print(f"âœ… å­—ç¬¦é›†å¤§å°: {total_chars:,} ä¸ªå­—ç¬¦")

    # å¯é€‰ï¼šæŠŠæ„å»ºçš„å­—ç¬¦é›†å¯¼å‡ºä¸º JSONï¼Œä¾› webapp å¤ç”¨ï¼ˆä¿è¯æµè§ˆå™¨ç¯å¢ƒä¸ Python ä¸€è‡´ï¼‰
    try:
        if args.export_charset:
            export_path = args.export_charset
            export_dir = os.path.dirname(export_path)
            if export_dir:
                os.makedirs(export_dir, exist_ok=True)
            data = {
                'generatedAt': time.strftime('%Y-%m-%dT%H:%M:%S', time.localtime()),
                'chars': [ord(c) for c in chars]
            }
            with open(export_path, 'w', encoding='utf-8') as cf:
                json.dump(data, cf, ensure_ascii=False)
            print(f"ğŸ—‚ï¸ å·²å¯¼å‡ºé¢„è®¡ç®—å­—ç¬¦é›†åˆ°: {export_path} (ä¾› webapp ä½¿ç”¨)")
    except Exception as e:
        print(f"âš ï¸ å¯¼å‡ºå­—ç¬¦é›†å¤±è´¥: {e}")

    # å¤„ç†å­—ç¬¦
    print("\nâš™ï¸  å¤„ç†å­—ç¬¦...")
    results = []
    replacement_records = []  # è®°å½•æ›¿æ¢å­—ç¬¦çš„ä¿¡æ¯
    processed = 0
    
    # åˆå§‹åŒ–æ€§èƒ½ç»Ÿè®¡
    timing_stats = {
        'render_time': 0.0,
        'crop_time': 0.0,
        'process_time': 0.0,
        'total_time': 0.0,
        'count': 0
    }
    
    overall_start = time.time()
    
    for ch in chars:
        proc = process_char(face, args.size, ch, ascender, args.white, enable_smoothing, timing_stats, keep_placeholder=args.keep_placeholder)
        if proc is None:
            continue
        if isinstance(proc, tuple) and proc[0] is None:
            # (None, replacement_info) è¡¨ç¤ºè¢«è·³è¿‡
            _, replacement_info = proc
            replacement_records.append(replacement_info)
            continue

        char_data, replacement_info = proc
        results.append(char_data)

        # è®°å½•æ›¿æ¢å­—ç¬¦
        if replacement_info:
            replacement_records.append(replacement_info)
        
        processed += 1
        
        # æ˜¾ç¤ºè¿›åº¦
        if processed % 500 == 0 or processed == total_chars:
            progress = processed / total_chars * 100
            print(f"  è¿›åº¦: {processed:,}/{total_chars:,} ({progress:.1f}%)")

    overall_time = time.time() - overall_start

    # æ·»åŠ æ§åˆ¶å­—ç¬¦ (0x00-0x1F)
    control_chars = [(cp, 0, 0, 0, 0, 0, b'') for cp in range(0, 0x20)]
    
    # åˆå¹¶å¹¶å»é‡
    char_map = {c[0]: c for c in results}
    # ç¡®ä¿ family_name / style_name ä¸­çš„å­—ç¬¦ä¹Ÿè¢«åŒ…å«ï¼ˆé¿å…åœ¨è®¾å¤‡ä¸Šæ˜¾ç¤ºä¸ºæ–¹æ¡†ï¼‰
    for name_src in (family_name, style_name):
        try:
            for ch in (name_src or ''):
                cp = ord(ch)
                if cp < 0x20:
                    continue
                if cp not in char_map:
                    # ç”Ÿæˆè¯¥å­—ç¬¦çš„æ¡ç›®å¹¶æ’å…¥
                    try:
                        char_data, _ = process_char(face, args.size, ch, ascender, args.white, enable_smoothing)
                        # char_data å½¢å¦‚ (codepoint, bw, bh, advance, xo, yo, bmp)
                        char_map[char_data[0]] = char_data
                        print(f"ğŸ”§ å·²æ·»åŠ ç¼ºå¤±çš„å­—ä½“åå­—ç¬¦: '{ch}' (U+{char_data[0]:04X}) åˆ°è¾“å‡ºå­—ç¬¦è¡¨")
                    except Exception as e:
                        print(f"âš ï¸ æ— æ³•ä¸ºå­—ä½“åå­—ç¬¦ç”Ÿæˆå­—å½¢ '{ch}': {e}")
        except Exception:
            pass

    final_chars = control_chars + [char_map[k] for k in sorted(char_map.keys()) if k >= 0x20]

    # ç”ŸæˆäºŒè¿›åˆ¶æ–‡ä»¶
    print(f"\nğŸ’¾ ç”ŸæˆäºŒè¿›åˆ¶æ–‡ä»¶...")
    output_path = generate_binary_font(final_chars, args.out, args.size, format_version=2, 
                                     family_name=family_name, style_name=style_name)
    # ç”Ÿæˆ .stats.json ä»¥ä¾¿ä¸æµè§ˆå™¨ç«¯ç»Ÿè®¡å¯¹æ¯”
    try:
        info = read_bin_font(output_path)
        entries = info['entries']
        total_bitmap_bytes = 0
        lens = []
        bwbh_count = {}
        max_len = 0
        min_len = None
        for cp, ent in entries.items():
            bmp = ent.get('bitmap', b'') or b''
            ln = len(bmp)
            total_bitmap_bytes += ln
            lens.append({'cp': int(cp), 'len': ln, 'bw': int(ent.get('bw', 0)), 'bh': int(ent.get('bh', 0)), 'advance': int(ent.get('advance', 0))})
            if ln > max_len:
                max_len = ln
            if min_len is None or ln < min_len:
                min_len = ln
            key = f"{int(ent.get('bw',0))}x{int(ent.get('bh',0))}"
            bwbh_count[key] = bwbh_count.get(key, 0) + 1

        if min_len is None:
            min_len = 0

        # histogram buckets
        hist = {}
        for it in lens:
            b = it['len']
            if b == 0:
                bucket = '0'
            elif b <= 8:
                bucket = '1-8'
            elif b <= 32:
                bucket = '9-32'
            elif b <= 128:
                bucket = '33-128'
            elif b <= 512:
                bucket = '129-512'
            else:
                bucket = '513+'
            hist[bucket] = hist.get(bucket, 0) + 1

        lens_sorted = sorted(lens, key=lambda x: x['len'], reverse=True)
        top_largest = lens_sorted[:50]
        sample_first = sorted(lens, key=lambda x: x['cp'])[:200]

        stats = {
            'generatedAt': time.strftime('%Y-%m-%dT%H:%M:%S', time.localtime()),
            'charCount': int(info.get('char_count', len(entries))),
            'totalBitmapBytes': int(total_bitmap_bytes),
            'binSizeBytes': int(os.path.getsize(output_path)) if os.path.isfile(output_path) else None,
            'avgBytesPerChar': (total_bitmap_bytes / len(entries)) if len(entries) else 0,
            'maxLen': int(max_len),
            'minLen': int(min_len),
            'histogram': hist,
            'bwbhCount': bwbh_count,
            'topLargest': top_largest,
            'sampleFirst': sample_first,
        }

        stats_path = os.path.splitext(output_path)[0] + '.stats.json'
        with open(stats_path, 'w', encoding='utf-8') as sf:
            json.dump(stats, sf, ensure_ascii=False, indent=2)
        print(f"ğŸ§¾ å·²å¯¼å‡ºç»Ÿè®¡æ–‡ä»¶: {stats_path}")
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆç»Ÿè®¡æ–‡ä»¶å¤±è´¥: {e}")
    
    # ä¿å­˜æ›¿æ¢å­—ç¬¦è®°å½•åˆ°æ–‡ä»¶
    if replacement_records:
        replacement_file = "replacement.txt"
        with open(replacement_file, 'w', encoding='utf-8') as f:
            f.write(','.join(replacement_records))
        print(f"ğŸ“ æ›¿æ¢å­—ç¬¦è®°å½•å·²ä¿å­˜åˆ°: {replacement_file} (å…± {len(replacement_records)} ä¸ª)")
    else:
        print("âœ… æ²¡æœ‰ä½¿ç”¨æ›¿æ¢å­—ç¬¦")
    
    # æœ€ç»ˆç»Ÿè®¡
    original_size = os.path.getsize(args.font)
    output_size = os.path.getsize(args.out)
    compression_ratio = output_size / original_size * 100
    
    print(f"\nğŸ‰ å®Œæˆ!")
    print(f"  è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"  å­—ç¬¦æ•°é‡: {len(final_chars):,}")
    print(f"  åŸå§‹å­—ä½“: {original_size:,} bytes")
    print(f"  ç”Ÿæˆæ–‡ä»¶: {output_size:,} bytes")
    print(f"  å‹ç¼©æ¯”: {compression_ratio:.1f}%")
    
    # å¦‚æœè¯·æ±‚ç”Ÿæˆ C++ ä»£ç æ–‡ä»¶
    if args.gen_cpp:
        cpp_out = args.cpp_out if args.cpp_out else os.path.splitext(args.out)[0] + '.cpp'
        print(f"\nğŸ”§ ç”Ÿæˆ C++ ä»£ç æ–‡ä»¶...")
        print(f"  è¾“å‡º: {cpp_out}")
        
        try:
            # ä½¿ç”¨ bin_to_progmem.py çš„é€»è¾‘ç”Ÿæˆ C++ æ–‡ä»¶
            from bin_to_progmem import generate_progmem_cpp
            
            info_cpp = generate_progmem_cpp(
                output_path,
                cpp_out,
                variable_name='progmem_font',
                chunk_size=16,
                add_stats=True
            )
            
            print(f"âœ… C++ ä»£ç æ–‡ä»¶å·²ç”Ÿæˆ")
            print(f"  æ–‡ä»¶: {cpp_out}")
            print(f"  Flash å ç”¨: {info_cpp['file_size']} å­—èŠ‚ ({info_cpp['file_size']/1024:.2f} KB)")
            print(f"  RAM å ç”¨: 0 å­—èŠ‚ (ä½¿ç”¨ PROGMEM)")
            
        except ImportError:
            print("âš ï¸ æ— æ³•å¯¼å…¥ bin_to_progmem æ¨¡å—ï¼Œè·³è¿‡ C++ ä»£ç ç”Ÿæˆ")
            print("   æç¤ºï¼šç¡®ä¿ bin_to_progmem.py åœ¨åŒä¸€ç›®å½•ä¸‹")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆ C++ ä»£ç æ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # æ€§èƒ½ç»Ÿè®¡
    if timing_stats['count'] > 0:
        print(f"\nâ±ï¸  æ€§èƒ½ç»Ÿè®¡:")
        print(f"  æ€»è€—æ—¶: {overall_time:.2f}s")
        print(f"  å¹³å‡æ¯å­—ç¬¦: {overall_time / timing_stats['count'] * 1000:.2f}ms")
        print(f"  å­—ä½“æ¸²æŸ“: {timing_stats['render_time']:.2f}s ({timing_stats['render_time']/overall_time*100:.1f}%)")
        print(f"  åŒºåŸŸè£å‰ª: {timing_stats['crop_time']:.2f}s ({timing_stats['crop_time']/overall_time*100:.1f}%)")
        print(f"  ä½å›¾å¤„ç†: {timing_stats['process_time']:.2f}s ({timing_stats['process_time']/overall_time*100:.1f}%)")
        if enable_smoothing:
            print(f"  è¾¹ç¼˜å¹³æ»‘: å·²å¯ç”¨ï¼ŒåŒ…å«åœ¨ä½å›¾å¤„ç†æ—¶é—´å†…")
        else:
            print(f"  è¾¹ç¼˜å¹³æ»‘: å·²ç¦ç”¨")

    # é¢å¤–è¯Šæ–­ï¼šä»åˆšç”Ÿæˆçš„ .bin è¯»å–å­—ä½“åå¹¶æ‰“å°åŸå§‹å­—èŠ‚ï¼ˆhexï¼‰ä¸è§£ç ç»“æœ
    try:
        if os.path.isfile(output_path):
            print("\nğŸ” éªŒè¯ .bin ä¸­ä¿å­˜çš„å­—ä½“åï¼ˆåŸå§‹å­—èŠ‚å’Œè§£ç ï¼‰:")
            try:
                info = read_bin_font(output_path)
                fam = info.get('family', '')
                sty = info.get('style', '')
                # è¯»å–åŸå§‹ bytesï¼šç›´æ¥ä»æ–‡ä»¶å¤´æå– 64 å­—èŠ‚å­—æ®µ
                with open(output_path, 'rb') as bf:
                    bf.seek(6)
                    fam_bytes = bf.read(64)
                    sty_bytes = bf.read(64)
                print(f"  family bytes (hex, {len(fam_bytes)}): {fam_bytes.hex()}")
                try:
                    print(f"  family decoded: {fam}")
                except Exception:
                    print(f"  family decoded: (decode error)")
                print(f"  style bytes (hex, {len(sty_bytes)}): {sty_bytes.hex()}")
                try:
                    print(f"  style decoded: {sty}")
                except Exception:
                    print(f"  style decoded: (decode error)")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•ä» .bin ä¸­è¯»å–å­—ä½“å: {e}")
    except Exception:
        pass
    
    # å¦‚æœè¯·æ±‚ç”Ÿæˆ demo å›¾ç‰‡ï¼Œä¼˜å…ˆä»åˆšç”Ÿæˆçš„ .bin æ¸²æŸ“ï¼ˆfast mode é£æ ¼ï¼‰ï¼Œå¤±è´¥å›é€€åˆ° face æ¸²æŸ“
    if args.demo:
        demo_text = args.demo
        if demo_text.startswith('@'):
            demo_file = demo_text[1:]
            if os.path.isfile(demo_file):
                with open(demo_file, 'r', encoding='utf-8') as f:
                    demo_text = f.read()
            else:
                print(f"âš ï¸ æŒ‡å®šçš„ demo æ–‡ä»¶ä¸å­˜åœ¨: {demo_file}")
                demo_text = "ç¤ºä¾‹æ–‡æœ¬"

        # ä¼˜å…ˆä½¿ç”¨ä» .bin æ¸²æŸ“ï¼ˆæ›´æ¥è¿‘è®¾å¤‡æ¸²æŸ“ï¼‰ï¼Œå¦‚æœ .bin ä¸å­˜åœ¨æˆ–æ¸²æŸ“å¤±è´¥å†å›é€€åˆ° face æ¸²æŸ“
        demo_ok = False
        try:
            if os.path.isfile(args.out):
                demo_ok = render_demo_from_bin(args.out, demo_text, args.demo_scale, args.demo_out)
        except Exception as e:
            print(f"âš ï¸ ä» .bin æ¸²æŸ“ demo æ—¶å‡ºé”™: {e}")

        if not demo_ok:
            if not render_demo_image(face, demo_text, args.size, args.demo_scale, args.demo_out, white_threshold=args.white, enable_smoothing=enable_smoothing):
                print("âš ï¸ ç”Ÿæˆ demo å›¾ç‰‡å¤±è´¥")

    return 0


if __name__ == "__main__":
    exit(main())